- 磁盘读写效率
造成磁盘访问低效的原因有两个，大量小的I/O操作，大量字节拷贝。为了避免这两个问题，Kafka协议基于一个自动将消息分组的消息集抽象，这种协议允许网络请求将消息聚合在一起，相较每次发送一条单独的消息，降低了网络请求往返时间。服务端在每次请求到来的时候，将消息块追加到日志文件后，而消费者每次获取大的线性的数据块。这种简单的优化带来了数量级的速度提升，批处理带来了更大的网络包，更多的磁盘线性操作，持续性的内存块等等特性，这就允许Kafka将突发的随机的消息写入转化为线性写入，流入消费者。另一个降低效率的因素是字节拷贝，在消息传输速率低时，这不是什么问题，但是在高负载下，字节拷贝对效率的影响就很大了。为了避免这种问题，Kafka发展了一种生产者，broker，和消费者共享的标准的二进制数据格式（如此在它们之间进行数据块传输时，不需要对数据进行任何修改）。维持这种通用的数据格式优化了最重要的操作：持久化日志块的网络传输。现代化的操作系统为数据从页面缓存传输到sokect里提供了大量的优化代码，在linux中通过调用[[sendfile系统函数]]来实现。Kafka通过使用[零拷贝](https://www.cnblogs.com/xiaolincoding/p/13719610.html)，数据只需复制一次到页面缓存中并且可以在消费时重复利用，而不是保存在内存中每次读取时都需要拷贝到用户空间中。这允许消息以接近网络链接的最大传输速率来消费。
页面缓存和sendfile的这种组合意味着，消费者经常消费的Kafka集群，几乎不会有磁盘访问，因为它们将完全从缓存中提取数据。
- 端到端批量压缩
Kafka在将数据发送到服务器时，支持将数据批量压缩，而不是每条消息单独的压缩。这种批信息将以压缩的形式写入日志文件中，只被消费者解压。
Kafka支持GZIP，Snappy，LZ4，ZStandard协议。